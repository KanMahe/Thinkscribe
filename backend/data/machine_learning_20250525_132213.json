[
    {
        "title": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms",
        "authors": [
            "Han Xiao",
            "Kashif Rasul",
            "Roland Vollgraf"
        ],
        "year": 2017,
        "abstract": "We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at this https URL",
        "url": "https://www.semanticscholar.org/paper/f9c602cc436a9ea2f9e7db48c77d924e09ce3c32"
    },
    {
        "title": "TensorFlow: A system for large-scale machine learning",
        "authors": [
            "Mart\u00edn Abadi",
            "P. Barham",
            "Jianmin Chen",
            "Z. Chen",
            "Andy Davis",
            "J. Dean",
            "M. Devin",
            "S. Ghemawat",
            "G. Irving",
            "M. Isard",
            "M. Kudlur",
            "J. Levenberg",
            "R. Monga",
            "Sherry Moore",
            "D. Murray",
            "Benoit Steiner",
            "P. Tucker",
            "Vijay Vasudevan",
            "Pete Warden",
            "M. Wicke",
            "Yuan Yu",
            "Xiaoqiang Zhang"
        ],
        "year": 2016,
        "abstract": "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.",
        "url": "https://www.semanticscholar.org/paper/4954fa180728932959997a4768411ff9136aac81"
    },
    {
        "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
        "authors": [
            "Mart\u00edn Abadi",
            "Ashish Agarwal",
            "P. Barham",
            "E. Brevdo",
            "Z. Chen",
            "C. Citro",
            "G. Corrado",
            "Andy Davis",
            "J. Dean",
            "M. Devin",
            "S. Ghemawat",
            "I. Goodfellow",
            "A. Harp",
            "G. Irving",
            "M. Isard",
            "Yangqing Jia",
            "R. J\u00f3zefowicz",
            "Lukasz Kaiser",
            "M. Kudlur",
            "J. Levenberg",
            "Dandelion Man\u00e9",
            "R. Monga",
            "Sherry Moore",
            "D. Murray",
            "C. Olah",
            "M. Schuster",
            "Jonathon Shlens",
            "Benoit Steiner",
            "I. Sutskever",
            "Kunal Talwar",
            "P. Tucker",
            "Vincent Vanhoucke",
            "Vijay Vasudevan",
            "F. Vi\u00e9gas",
            "O. Vinyals",
            "Pete Warden",
            "M. Wattenberg",
            "M. Wicke",
            "Yuan Yu",
            "Xiaoqiang Zheng"
        ],
        "year": 2016,
        "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
        "url": "https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d"
    },
    {
        "title": "A Survey on Bias and Fairness in Machine Learning",
        "authors": [
            "Ninareh Mehrabi",
            "Fred Morstatter",
            "N. Saxena",
            "Kristina Lerman",
            "A. Galstyan"
        ],
        "year": 2019,
        "abstract": "With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.",
        "url": "https://www.semanticscholar.org/paper/0090023afc66cd2741568599057f4e82b566137c"
    }
]